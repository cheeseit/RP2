An introduction to the background.

\subsection{Kronecker graph}
The graph that is used by the Graph500 is the Kronecker graph\cite{leskovec2010kronecker}. This is because a Kronecker graph has some nice properties which are also seen in graph that can be seen in the real world.
%TODO list of properties which are important to the graph500.
%TODO Say something about the properties of the graph. is a tree, so undirected.

\subsection{Graph compression}
Something about Sparse matrixes, because it is kroneck graph and ways of reducing the amount data needs to be stored while using such a graph.

\subsection{Reference Implementations}
As mentioned in the section \ref{related-work} the reference implementations have been studied in detail. The reference which will be used in this project is the  simple one. This has been chosen because it is the most simple to understand, has been thoroughly studied and requires the least amount of RAM on each of the nodes. The decision made to run everything on the RAM was done, because this is easier to implement no shared file system was needed. 

Here a brief description of the algorithm will be given a more detailed explanation can be found in the by Suzumara et al.\cite{suzumura2011performance}.
 
The implementation uses 2 queues for the BFS. The first queue is used to store all nodes that should still be visited in this iteration. The second queue is used to store all the nodes that should be visited in the next iteration. When the first queue is empty the roles will be swapped of the queues and the next iteration will start. This is done until there are no more nodes that should be visited.
After each level a synchronization is done before the next level can begin. 
%The synchronization is needed because otherwise nodes from the wrong level can be put in the wrong queue.

The nodes are evenly distributed between the processes. This is done by looking at the rank of the process and the modulo of the number of processes to divide them.

The graph is stored in a CSR way to minimize the amount of data that needs to be stored in the ram.

The paper that was previously mentioned also gives an estimate of the amount of communication in the simple algorithm. The formula is:\\
\begin{equation}
\label{eq:communication_size}
C(n, M) = A * B * C * D (bytes).
\end{equation}
Where $A = M*2, B = (n-1)/n, C=2, and D=8$ \\

For example, if s $=$ 32 and n $=$ 128 (128 MPI processes), then the total communication 
data volume $C(128, M)$ is calculated as $2^{32}$ $*$ 16 $*$ 2 $*$ $(127/128)$ $*$ 2 $*$ 8 = 2032 GB (2 TB). As previously noted, the entire graph for M(32) was 
1.03 TB, so the amount of data was doubled.